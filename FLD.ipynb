{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "#from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据读取\n",
    "train_set_1 = pd.read_csv('train_hf_data.csv',header=0,index_col=0)\n",
    "train_set_1_label = pd.read_csv('train_hf_label.csv',header=0,index_col=0)\n",
    "test_set_1 = pd.read_csv('test_hf_data.csv',header=0,index_col=0)\n",
    "test_set_1_label = pd.read_csv('test_hf_label.csv',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计函数清理不在给定范围内的样本\n",
    "def data_clean(data):\n",
    "    D = data\n",
    "    D = D.drop(D[(D.age < 40) | (D.age > 95)].index)\n",
    "    D = D.drop(D[(D.creatinine_phosphokinase < 23) | (D.creatinine_phosphokinase > 7861)].index)\n",
    "    D = D.drop(D[(D.ejection_fraction < 14) | (D.ejection_fraction > 80)].index)\n",
    "    D = D.drop(D[(D.platelets < 25010) | (D.platelets > 850000)].index)\n",
    "    D = D.drop(D[(D.serum_creatinine < 0.5) | (D.serum_creatinine > 9.4)].index)\n",
    "    D = D.drop(D[(D.serum_sodium < 114) | (D.serum_sodium > 148)].index)\n",
    "    D = D.drop(D[(D.time < 4) | (D.time > 285)].index)\n",
    "    return D.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计函数将数据按附件给的正常范围进行归一化处理\n",
    "#这个函数是用的老师给的数据范围进行归一化的\n",
    "def normalization(data):\n",
    "    D = np.array(data)\n",
    "    min_range = np.array([[40,55],[0,1],[23,7838],[0,1],[14,66],[0,1],[25010,825000],[0.5,8.9],[114,34],[0,1],[0,1],[4,281]])\n",
    "    def maxminNormalize(X,X_min,X_range):\n",
    "        return (X-X_min) / X_range\n",
    "    for i in range(len(D[0]-1)):\n",
    "        for j in range(len(D[:,0]-1)):\n",
    "            D[j][i] = maxminNormalize(D[j][i],min_range[i][0],min_range[i][1])\n",
    "    return D     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运算出的参数矩阵为: [[-0.00549126  0.00046238 -0.00393476 -0.00062357  0.01064647  0.00086281\n",
      "   0.00301802 -0.01076436  0.00561992  0.00034739 -0.00018436  0.01238021]]\n",
      "训练集中标签为0的误分类个数： 0\n",
      "训练集中标签为1的误分类个数： 74\n",
      "测试集中标签为0的误分类个数： 0\n",
      "测试集中标签为1的误分类个数： 20\n",
      "Error rate:  0.3389830508474576\n"
     ]
    }
   ],
   "source": [
    "#对训练集清洗\n",
    "train_set_1_merge = pd.concat([train_set_1,train_set_1_label],axis=1)#为了数据清洗方便，先将标签合并上去\n",
    "train_set_1_merge = data_clean(train_set_1_merge)#清除不在范围的样本及标签\n",
    "#为了便于运算，重新创建两个dataframe，data_0只有标签为0的数据；data_1只有标签为1的数据\n",
    "data_0 = train_set_1_merge\n",
    "data_0 = data_0.drop(data_0[data_0.label == 1].index).reset_index(drop=True)\n",
    "data_1 = train_set_1_merge\n",
    "data_1 = data_1.drop(data_1[data_1.label == 0].index).reset_index(drop=True)\n",
    "y_0 = math.log(len(data_1['label']) / len(data_0['label']),10)#计算判定时需要的阈值\n",
    "#删除标签\n",
    "data_0 = data_0.drop('label',axis=1)\n",
    "data_1 = data_1.drop('label',axis=1)\n",
    "data_0 = normalization(data_0)#标准化标签为0的数据\n",
    "m_0 = np.mean(data_0,axis=0)#计算标签为0的均值向量\n",
    "s_0 = np.zeros(shape=(len(m_0),len(m_0)))#定义标签为0的类内离散度矩阵\n",
    "for i in range(len(data_0)-1):\n",
    "    s_0 += np.dot((data_0[i]-m_0).reshape(12,1),(data_0[i]-m_0).reshape(1,12))#计算标签为0的类内离散度矩阵\n",
    "data_1 = normalization(data_1)#标准化标签为1的数据\n",
    "m_1 = np.mean(data_1,axis=0)#计算标签为1的均值向量\n",
    "s_1 = np.zeros(shape=(len(m_0),len(m_0)))#定义标签为1的类内离散度矩阵\n",
    "for i in range(len(data_1)-1):\n",
    "    s_1 += np.dot((data_1[i]-m_0).reshape(12,1),(data_1[i]-m_0).reshape(1,12))#计算标签为1的类内离散度矩阵\n",
    "s = np.mat(s_0 + s_1)#计算总类内离散度矩阵\n",
    "w = np.dot(s.I,(m_0 - m_1))#计算参数矩阵\n",
    "print('运算出的参数矩阵为:',w)\n",
    "#以下为验证训练集的收敛情况\n",
    "count_0 = 0\n",
    "for i in range(len(data_0)-1):\n",
    "    if np.dot(w,data_0[i]-1/2*(m_0 + m_1)) <= y_0:\n",
    "        count_0 += 1\n",
    "print('训练集中标签为0的误分类个数：',count_0)\n",
    "count_1 = 0\n",
    "for i in range(len(data_1)-1):\n",
    "    if np.dot(w,data_1[i]-1/2*(m_0 + m_1)) >= y_0:\n",
    "        count_1 += 1\n",
    "print('训练集中标签为1的误分类个数：',count_1)\n",
    "#对测试集清洗\n",
    "test_set_1_merge = pd.concat([test_set_1,test_set_1_label],axis=1)#为了数据清洗方便，先将标签合并上去\n",
    "test_set_1_merge = data_clean(test_set_1_merge)#清除不在范围的样本及标签\n",
    "#对测试集进行相同的操作\n",
    "test_0 = test_set_1_merge\n",
    "test_0 = test_0.drop(test_0[test_0.label == 1].index).reset_index(drop=True)\n",
    "test_1 = test_set_1_merge\n",
    "test_1 = test_1.drop(test_1[test_1.label == 0].index).reset_index(drop=True)\n",
    "#删除标签\n",
    "test_0 = test_0.drop('label',axis=1)\n",
    "test_1 = test_1.drop('label',axis=1)\n",
    "test_0 = normalization(test_0)\n",
    "test_1 = normalization(test_1)\n",
    "#计算测试集中的误分类个数，并输出错误率\n",
    "count_0 = 0\n",
    "for i in range(len(test_0)-1):\n",
    "    if np.dot(w,test_0[i]-1/2*(m_0 + m_1)) <= y_0:\n",
    "        count_0 += 1\n",
    "print('测试集中标签为0的误分类个数：',count_0)\n",
    "count_1 = 0\n",
    "for i in range(len(test_1)-1):\n",
    "    if np.dot(w,test_1[i]-1/2*(m_0 + m_1)) >= y_0:\n",
    "        count_1 += 1\n",
    "print('测试集中标签为1的误分类个数：',count_1)\n",
    "print(\"Error rate: \",(count_0 + count_1) / len(test_set_1_merge['label']))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
