{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的模块\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据读取\n",
    "train_set_1 = pd.read_csv('train_hf_data.csv',header=0,index_col=0)\n",
    "train_set_1_label = pd.read_csv('train_hf_label.csv',header=0,index_col=0)\n",
    "test_set_1 = pd.read_csv('test_hf_data.csv',header=0,index_col=0)\n",
    "test_set_1_label = pd.read_csv('test_hf_label.csv',header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计函数清理不在给定范围内的样本\n",
    "def data_clean(data):\n",
    "    D = data\n",
    "    D = D.drop(D[(D.age < 40) | (D.age > 95)].index)\n",
    "    D = D.drop(D[(D.creatinine_phosphokinase < 23) | (D.creatinine_phosphokinase > 7861)].index)\n",
    "    D = D.drop(D[(D.ejection_fraction < 14) | (D.ejection_fraction > 80)].index)\n",
    "    D = D.drop(D[(D.platelets < 25010) | (D.platelets > 850000)].index)\n",
    "    D = D.drop(D[(D.serum_creatinine < 0.5) | (D.serum_creatinine > 9.4)].index)\n",
    "    D = D.drop(D[(D.serum_sodium < 114) | (D.serum_sodium > 148)].index)\n",
    "    D = D.drop(D[(D.time < 4) | (D.time > 285)].index)\n",
    "    return D.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计函数将数据按附件给的正常范围进行归一化处理\n",
    "#这个函数是用的老师给的数据范围进行归一化的\n",
    "def normalization(data):\n",
    "    D = np.array(data)\n",
    "    min_range = np.array([[40,55],[0,1],[23,7838],[0,1],[14,66],[0,1],[25010,825000],[0.5,8.9],[114,34],[0,1],[0,1],[4,281]])\n",
    "    def maxminNormalize(X,X_min,X_range):\n",
    "        return (X-X_min) / X_range\n",
    "    for i in range(len(D[0]-1)):\n",
    "        for j in range(len(D[:,0]-1)):\n",
    "            D[j][i] = maxminNormalize(D[j][i],min_range[i][0],min_range[i][1])\n",
    "    return D     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对数据进行清洗\n",
    "#对训练集清洗\n",
    "train_set_1_merge = pd.concat([train_set_1,train_set_1_label],axis=1)#为了数据清洗方便，先将标签合并上去\n",
    "train_set_1_merge = data_clean(train_set_1_merge)#清除不在范围的样本及标签\n",
    "train_set_1 = train_set_1_merge.drop('label',axis=1)#将特征矩阵分离出来\n",
    "train_set_1_label = train_set_1_merge['label']#将标签分离出来\n",
    "#对测试集清洗\n",
    "test_set_1_merge = pd.concat([test_set_1,test_set_1_label],axis=1)#为了数据清洗方便，先将标签合并上去\n",
    "test_set_1_merge = data_clean(test_set_1_merge)#清除不在范围的样本及标签\n",
    "test_set_1 = test_set_1_merge.drop('label',axis=1)#将特征矩阵分离出来\n",
    "test_set_1_label = test_set_1_merge['label']#将标签分离出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据转换成多维数组并进行标准化\n",
    "#将数据全部转换为矩阵\n",
    "train_set_1 = np.array(train_set_1)\n",
    "test_set_1 = np.array(test_set_1)\n",
    "train_set_1_label = np.array(train_set_1_label)\n",
    "test_set_1_label = np.array(test_set_1_label)\n",
    "#对训练集及测试集的特征矩阵进行归一化\n",
    "X_train = normalization(train_set_1)\n",
    "X_test = normalization(test_set_1)\n",
    "y_train = train_set_1_label\n",
    "y_test = test_set_1_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression()#将scikit-learn包中的LogisticRegression模块重命名为LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.fit(X_train,y_train)#运用训练集训练模型，参数全部使用默认值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集错误率为： 0.15899581589958156\n"
     ]
    }
   ],
   "source": [
    "print('训练集错误率为：',1 - LR.score(X_train,y_train))#计算模型运用在训练集上的错误率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.875     , 0.75      , 0.75      , 0.75      , 0.625     ,\n",
       "       0.83333333, 0.875     , 0.79166667, 0.91666667, 0.7826087 ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LR, X_train, y_train, cv=10)#计算k折交叉验证的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集错误率为： 0.2033898305084746\n"
     ]
    }
   ],
   "source": [
    "print('测试集错误率为：',1 - LR.score(X_test,y_test))#计算模型运用在测试集上的错误率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
